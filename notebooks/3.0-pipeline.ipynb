{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#supressing warnings for readability\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To plot pretty figures directly within Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# choose your own style: https://matplotlib.org/3.1.0/gallery/style_sheets/style_sheets_reference.html\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Go to town with https://matplotlib.org/tutorials/introductory/customizing.html\n",
    "# plt.rcParams.keys()\n",
    "mpl.rc('axes', labelsize=14, titlesize=14)\n",
    "mpl.rc('figure', titlesize=20)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# contants for figsize\n",
    "S = (8,8)\n",
    "M = (12,12)\n",
    "L = (14,14)\n",
    "\n",
    "# pandas options\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "pd.set_option(\"display.max.rows\", None)\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "# df_client = pd.read_csv('../data/processed/client_train.csv')\n",
    "# df_invoice = pd.read_csv('../data/processed/invoice_train.csv')\n",
    "# df_merged = pd.merge(df_client, df_invoice, on='client_id')\n",
    "df_merged = pd.read_csv('../data/processed/merged_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4452681 entries, 0 to 4452680\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Dtype \n",
      "---  ------                        ----- \n",
      " 0   Unnamed: 0                    int64 \n",
      " 1   Unnamed: 0_x                  int64 \n",
      " 2   district                      int64 \n",
      " 3   client_id                     object\n",
      " 4   client_cat                    int64 \n",
      " 5   region                        int64 \n",
      " 6   creation_date                 object\n",
      " 7   target                        bool  \n",
      " 8   Unnamed: 0_y                  int64 \n",
      " 9   invoice_date                  object\n",
      " 10  tarif_type                    int64 \n",
      " 11  counter_number                int64 \n",
      " 12  counter_status                int64 \n",
      " 13  counter_code                  int64 \n",
      " 14  counter_score                 int64 \n",
      " 15  counter_coefficient           int64 \n",
      " 16  consommation_level_1          int64 \n",
      " 17  consommation_level_2          int64 \n",
      " 18  consommation_level_3          int64 \n",
      " 19  consommation_level_4          int64 \n",
      " 20  old_index                     int64 \n",
      " 21  new_index                     int64 \n",
      " 22  month                         int64 \n",
      " 23  counter_type                  object\n",
      " 24  consommation_total_not1       int64 \n",
      " 25  consommation_total            int64 \n",
      " 26  bin_counter_number            object\n",
      " 27  bin_cons_1                    object\n",
      " 28  consommation_level_2above100  bool  \n",
      " 29  consommation_level_3above100  bool  \n",
      " 30  consommation_level_4above100  bool  \n",
      " 31  consommation_totalabove100    bool  \n",
      " 32  same_month                    bool  \n",
      "dtypes: bool(6), int64(21), object(6)\n",
      "memory usage: 942.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4452681 entries, 0 to 4452680\n",
      "Columns: 33 entries, Unnamed: 0 to same_month\n",
      "dtypes: bool(6), category(6), uint16(3), uint32(10), uint64(1), uint8(7)\n",
      "memory usage: 336.9 MB\n"
     ]
    }
   ],
   "source": [
    "# reduce memory: strings to categories\n",
    "\n",
    "# int64 to smallest, unsigned int\n",
    "for col in df_merged.select_dtypes(include='int64').columns:\n",
    "    df_merged[col] = pd.to_numeric(df_merged[col], downcast='unsigned')\n",
    "\n",
    "for col in df_merged.select_dtypes(include='object').columns:\n",
    "    df_merged[col] = df_merged[col].astype('category')\n",
    "\n",
    "df_merged.info(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4452681 entries, 0 to 4452680\n",
      "Data columns (total 33 columns):\n",
      " #   Column                        Dtype   \n",
      "---  ------                        -----   \n",
      " 0   Unnamed: 0                    uint32  \n",
      " 1   Unnamed: 0_x                  uint32  \n",
      " 2   district                      uint8   \n",
      " 3   client_id                     category\n",
      " 4   client_cat                    uint8   \n",
      " 5   region                        uint16  \n",
      " 6   creation_date                 category\n",
      " 7   target                        bool    \n",
      " 8   Unnamed: 0_y                  uint32  \n",
      " 9   invoice_date                  category\n",
      " 10  tarif_type                    uint8   \n",
      " 11  counter_number                uint64  \n",
      " 12  counter_status                uint8   \n",
      " 13  counter_code                  uint16  \n",
      " 14  counter_score                 uint8   \n",
      " 15  counter_coefficient           uint8   \n",
      " 16  consommation_level_1          uint32  \n",
      " 17  consommation_level_2          uint32  \n",
      " 18  consommation_level_3          uint16  \n",
      " 19  consommation_level_4          uint32  \n",
      " 20  old_index                     uint32  \n",
      " 21  new_index                     uint32  \n",
      " 22  month                         uint8   \n",
      " 23  counter_type                  category\n",
      " 24  consommation_total_not1       uint32  \n",
      " 25  consommation_total            uint32  \n",
      " 26  bin_counter_number            category\n",
      " 27  bin_cons_1                    category\n",
      " 28  consommation_level_2above100  bool    \n",
      " 29  consommation_level_3above100  bool    \n",
      " 30  consommation_level_4above100  bool    \n",
      " 31  consommation_totalabove100    bool    \n",
      " 32  same_month                    bool    \n",
      "dtypes: bool(6), category(6), uint16(3), uint32(10), uint64(1), uint8(7)\n",
      "memory usage: 336.9 MB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'target'\n",
    "commont_col = 'client_id'\n",
    "\n",
    "client_cat_col = ['district', 'client_id', 'client_cat', 'region']\n",
    "client_dt_col = ['creation_date']\n",
    "client_bool_col = ['target']\n",
    "\n",
    "invoice_cat_col = ['client_id', 'tarif_type', 'counter_status', 'counter_code', 'month', 'counter_type']\n",
    "invoice_ordinal_col = ['counter_status']\n",
    "invoice_dt_col = ['invoice_date']\n",
    "invoice_num_col = ['counter_number', 'counter_score', 'counter_coefficient', 'consommation_level_1', 'consommation_level_2', 'consommation_level_3', 'consommation_level_4', 'old_index', 'new_index']\n",
    "consom_col = ['consommation_level_1', 'consommation_level_2', 'consommation_level_3', 'consommation_level_4']\n",
    "consom_without1_col = ['consommation_level_2', 'consommation_level_3', 'consommation_level_4']\n",
    "id_cols = ['client_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(df, column, num_bins):\n",
    "    # Create bins\n",
    "    edge, bins = pd.qcut(df[column], q=num_bins, retbins=True)\n",
    "    # labels = [str(interval) for interval in bins.categories]\n",
    "\n",
    "    # Assign labels to each bin\n",
    "    labels = []\n",
    "    for x in range(1, len(bins)):\n",
    "        labels.append(f'{bins[x-1]} - {bins[x]}')\n",
    "\n",
    "    # # Create the new categorical column based on the bin labels\n",
    "    return pd.qcut(df[column], q=num_bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ConsoAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_total=True, bin=False, above_100=False):\n",
    "        self.add_total = add_total\n",
    "        self.bin = bin\n",
    "        self.above_100 = above_100\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "        ret = []\n",
    "        if self.add_total:\n",
    "            data['total_consom'] = X[data.columns].sum(axis=1)\n",
    "            ret.append('total_consom')\n",
    "        if self.above_100:\n",
    "            for col in data.columns:\n",
    "                data[col + '_above_100'] = X[col].map(lambda x: True if x > 100 else False)\n",
    "                ret.append(col + '_above_100')\n",
    "        if self.bin:\n",
    "            for col in data.columns:\n",
    "                if col == 'consommation_level_1':\n",
    "                    data[col + 'bin'] = bin_data(X, 'consommation_level_1', 9)\n",
    "                    ret.append(col + 'bin')\n",
    "                    continue\n",
    "        return data[ret]\n",
    "\n",
    "class DateAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "        ret = []\n",
    "        for col in data.columns:\n",
    "            data[col] = pd.to_datetime(data[col])\n",
    "            data[col + 'month'] = data[col].dt.month\n",
    "            data[col + 'year'] = data[col].dt.year\n",
    "            ret.append(col + 'month')\n",
    "            ret.append(col + 'year')\n",
    "        return data[ret]\n",
    "    \n",
    "class NumericalToCategoricalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.encoders = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(X[col])\n",
    "            self.encoders[col] = encoder\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed = []\n",
    "        for col in X.columns:\n",
    "            encoder = self.encoders[col]\n",
    "            transformed.append(encoder.transform(X[col]))\n",
    "        transformed = np.vstack(transformed).T\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "consom_col_num = Pipeline([\n",
    "    ('attribs_adder', ConsoAttributesAdder()),\n",
    "])\n",
    "\n",
    "consom_col_cat = Pipeline([\n",
    "    ('attribs_adder', ConsoAttributesAdder(add_total=False, above_100=True)),\n",
    "])\n",
    "\n",
    "consom_col_bin = Pipeline([\n",
    "    ('attribs_adder', ConsoAttributesAdder(add_total=False, bin=True)),\n",
    "    ('one_hot_encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "date_pipe = Pipeline([\n",
    "    ('attribs_adder', DateAttributesAdder())\n",
    "])\n",
    "\n",
    "one_hot_pipe = Pipeline([\n",
    "    ('label_encoder', NumericalToCategoricalTransformer()),\n",
    "    ('one_hot_encoder', OneHotEncoder(sparse=False)),\n",
    "])\n",
    "\n",
    "# ColumnTransformer on all included columns.\n",
    "# Note columns that are not specified are dropped by default\n",
    "transformers = {\n",
    "    \"consom_num\": (\"consom_num\", consom_col_num, consom_col),\n",
    "    \"consom_cat\": (\"consom_cat\", consom_col_cat, consom_col),\n",
    "    \"consom_bin\": (\"consom_bin\", consom_col_bin, consom_col),\n",
    "    \"num_pipe\": (\"num_pipe\", num_pipe, invoice_num_col),\n",
    "    \"date_pipe\": (\"date_pipe\", date_pipe, invoice_dt_col+client_dt_col),\n",
    "    \"ord_cat_pipe\": (\"ord_cat_pipe\", OrdinalEncoder(), invoice_ordinal_col),\n",
    "    'one_hot_pipe': ('one_hot_pipe', one_hot_pipe, [x for x in invoice_cat_col + client_cat_col if x not in invoice_ordinal_col + id_cols])\n",
    "}\n",
    "prep = ColumnTransformer(\n",
    "    transformers=[v for _, v in transformers.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.20000000e+01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -7.42677148e-02,  5.01333668e-01,\n",
       "       -9.71455712e-03, -4.43843763e-01, -8.89030198e-02, -1.60238307e-01,\n",
       "       -6.09058051e-02, -8.59368943e-02, -9.60323709e-02,  3.00000000e+00,\n",
       "        2.01400000e+03,  1.20000000e+01,  1.99400000e+03,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        1.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = prep.fit_transform(df_merged)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "False    92.11\n",
       "True      7.89\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_merged['target']\n",
    "labels.value_counts() / len(df_merged) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = sampler.fit_resample(X_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/var_store/X_resampled.pkl', 'wb') as f:\n",
    "    pickle.dump(X_resampled, f)\n",
    "\n",
    "with open('../data/var_store/y_resampled.pkl', 'wb') as f:\n",
    "    pickle.dump(y_resampled, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('../data/var_store/X_resampled.pkl', 'rb') as f:\n",
    "#     X_resampled = pickle.load(f)\n",
    "\n",
    "# with open('../data/var_store/y_resampled.pkl', 'rb') as f:\n",
    "#     y_resampled = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
